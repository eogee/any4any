# any4any: One-stop API service for LLM conversations, content preview and editing, voice recognition, text-to-speech, document reranking, text embedding, knowledge base system, and MCP services ğŸš€

<div align="center">  
  <a href="../README.md">ä¸­æ–‡ç®€ä½“ Â·  </a>
  English
</div>  

## âœ¨Features  

**Core Features**: After starting and running this project, you can expose almost all types of models as OpenAI-API compatible interfaces, which can be added to any model management application and track user conversation history. Here's an introduction to each functional module:

- **Conversation Management**: Supports multi-platform LLM conversation management, exposing local models as OpenAI-API compatible interfaces that can be added to any model management application, with user conversation history tracking
- **Preview Mode**: Supports LLM response content preview and editing functionality
- **DingTalk Bot**: Supports DingTalk bot message processing
- **Speech-to-Text**: Convert audio files to text (supports multiple languages)
- **Text-to-Speech**: Convert text to speech files (supports multiple voice styles). Default voice: `zh-CN-XiaoyiNeural`
- **Knowledge Base**: Provides independent embedding and reranking capabilities, can build knowledge base systems based on ChromaDB vector database
- **MCP Service**: Supports building MCP tools, interfaces, and can be invoked by any MCP client
- **API Documentation**: Automatically generated API documentation accessible via browser at: http://localhost:8888/docs#/

## ğŸ‰Updates  

**2025.10.08(V0.1.1): Added Embedding Module**

New Features:
- **Embedding Module**: Complete embedding model support, including document processing, vector storage, retrieval engine, etc.
- **Document Processing**: Support for document parsing, chunking, vectorization and other processing flows
- **Vector Storage**: Efficient vector storage and management mechanism
- **Retrieval Engine**: Document retrieval functionality based on similarity
- **Knowledge Base Server**: Provides knowledge base creation, management and query services
- **OpenAI API Compatible Interface**: Supports calling methods consistent with OpenAI embedding API
- [Knowledge Base System Documentation.md](./KnowledgeBaseSystemDocumentation.md)

**2025.9.26(V0.1.0): Added conversation management and preview mode features**

New Features:
- **Conversation Management**: Supports multi-platform conversation management, tracking user conversation history, and enabling context-aware continuous dialogue
- **Preview Mode**: Supports content preview and editing functionality, allowing users to preview and modify generated content. Access via browser: http://localhost:8888/index/
- **DingTalk Bot Integration**: Supports DingTalk bot message processing, enabling interaction with the system within DingTalk
- **Enhanced User Authentication**: Added API key-based authentication mechanism to improve system security
- **Database Conversation Storage**: Stores conversation data in MySQL database, supporting persistence and querying
- [Conversation Management System Documentation.md](./ConversationManagementSystemDocumentation.md)

Updates:
- **Restructured Project Architecture**: Added data_models module for managing data models, servers module for managing services, and static directory for managing static files

**2025.5.24(V0.0.6): Added support for building MCP services**

New Features:
- **MCP Tool Construction**: You can add any MCP tools in `core/mcp_tools.py`. By default, it provides addition, subtraction, multiplication, and division of two integers.
- **MCP Tool Registration**: Import the corresponding module in `app.py`, such as `from core.mcp_tools import add, sub, mul, div`, and register them in the `mcp.tool()` function.
- **MCP Service Startup**: Run the start command: `python cli.py` or `a4a-run`, and the service will be available at: http://localhost:9999

Example documents for calling in Dify and Cherrystudio can be found at: [mcp_test.md](./docs/mcp_test.md) (to be completed later).

Dify workflow file: [mcp_test.yml](./workflows/mcp_test.yml).



## ğŸ› ï¸Prerequisites  

- **WSL2 (Windows Subsystem for Linux)**: Required for Windows systems.  
- **Conda (Anaconda or Miniconda)**: For Python environment management.  
- **Docker Desktop**: Docker desktop application for Windows to run Dify services.  
- **MySQL**: For storing conversation data.

## ğŸ“¥Installation Guide  

### 1. Clone the Project  

```bash  
git clone https://github.com/eogee/any4any.git  
# Or  
git clone https://gitee.com/eogee/any4any.git  
# Or
git clone https://gitcode.com/eogee/any4any.git
```  

You can also download the project via cloud storage: https://pan.quark.cn/s/fbe126d5bd75

### 2. Download Models  

```bash  
# Ensure git-lfs is installed (https://git-lfs.com) for large file downloads
# You can download models from huggingface.co, modelscoup.com, or hf-mirror.com sites. Here we use huggingface.co as an example
# æ‚¨å¯åœ¨huggingface.co, modelscoup.com, hf-mirror.comç«™ç‚¹ä¸­ä¸‹è½½æ¨¡å‹ï¼Œæ­¤å¤„ä»¥huggingface.coä¸ºä¾‹
git lfs install  

# Download the speech recognition model: SenseVoiceSmall  
git clone https://huggingface.co/FunAudioLLM/SenseVoiceSmall  

# Download the reranking model: bge-reranker-base    
git clone https://huggingface.co/BAAI/bge-reranker-base  

# Download the LLM model: Qwen3-1.7B  
git clone https://huggingface.co/Qwen/Qwen3-1.7B

# Download the Embedding model: bge-small-zh-v1.5
git clone https://huggingface.co/BAAI/bge-small-zh-v1.5  
```  

### 3. Create a Conda Environment  

```bash  
# Create the conda environment  
conda create -n any4any python=3.10  
# Activate the environment  
conda activate any4any  
```  

### 4. Install Dependencies  

```bash  
# Install ffmpeg  
sudo apt-get install ffmpeg  
# Verify ffmpeg installation  
ffmpeg -version  
# Install other dependencies  
pip install -r requirements.txt  
```  

### 5. Configure Environment Variables  

Copy the example configuration file and modify as needed:

```bash
cp .env.example .env
```

Edit the `.env` file to configure:
- Database connection information
- Model paths
- API keys
- Other custom configurations

### 6. Start the Service  

```bash  
# Start the service directly  
python cli.py  

# Or use the shortcut command (WSL/Linux environments):  
# Permanently install the any4any-run command:  
sudo cp a4a-run.sh /usr/local/bin/a4a-run
sudo chmod +x /usr/local/bin/a4a-run
# After installation, use directly:  
a4a-run 
```  

The service will run at the following ports:
- Main service: http://localhost:8888
- MCP service: http://localhost:9999
- DingTalk service: http://localhost:6666

### 7. Add and Call Models in Other Model Platform Applications (Dify as an Example)  

**7.1 Check the Host Machine's IP Address**  
Run the `ifconfig` command in WSL to check the host machine's IP address.  
```bash  
eth0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500  
        inet 172.21.56.14  netmask 255.255.240.0  broadcast 172.21.63.255  
```  
Here, `172.21.56.14` is the host machine's IP address.  

**7.2 Import the TTS Model**  
Start Docker and ensure the Dify service is running.  
Import and install the plugin `langgenius-openai_api_compatible_0.0.16.difypkg` into Dify.  
Open the `OpenAI-API-compatible` plugin, click `Add Model`, and configure as follows:  
```
Model Type: TTS  
Model Name: edge-tts  
API Endpoint URL: `http://172.21.56.14:8888/v1` or `http://host.docker.internal:8888/v1`  
API Key: EMPTY  
Available Voices (comma-separated): zh-CN-XiaoyiNeural  
Other fields can be left blank.  
```  

**7.3 Import the ASR Model**  
Configure the model path:  
```python  
# config.py  
# .env file
ASR_MODEL_DIR=/mnt/c/models/SenseVoiceSmall  # Replace with your local ASR model path  
```  

Open the `OpenAI-API-compatible` plugin, click `Add Model`, and configure as follows:  
```
Model Type: Speech2text  
Model Name: SenseVoiceSmall  
API Key: EMPTY  
API Endpoint URL: `http://172.21.56.14:8888/v1` or `http://host.docker.internal:8888/v1`  
```  

**7.4 Import the Rerank Model**  
Configure the model path:  
```
# .env file
RERANK_MODEL_DIR=/mnt/c/models/bge-reranker-base  # Replace with your local rerank model path
```  

Open the `OpenAI-API-compatible` plugin, click `Add Model`, and configure as follows:  
```
Model Type: rerank  
Model Name: bge-reranker-base  
API Key: EMPTY  
API Endpoint URL: `http://172.21.56.14:8888/v1` or `http://host.docker.internal:8888/v1`  
```  

**7.5 Import the LLM Model**  
Configure the model path:  
```python  
# .env file
LLM_MODEL_DIR=/mnt/c/models/Qwen3-1.7B  # Replace with your local LLM model path  
```  

Open the `OpenAI-API-compatible` plugin, click `Add Model`, and configure as follows:  
```
Model Type: LLM  
Model Name: Qwen3-1.7B  
API Key: EMPTY  
API Endpoint URL: `http://172.21.56.14:8888/v1` or `http://host.docker.internal:8888/v1`  
```  

**7.6 Import Embedding Model**

Configure the model path:
```
# .env file
EMBBEDING_MODEL_DIR = "/mnt/c/models/bge-small-zh-v1.5"  # Replace with your local Embedding model path
```

Open the `OpenAI-API-compatible` plugin, click `Add Model`, and configure as follows:
```
Model Type: Embedding
Model Name: bge-small-zh-v1.5
API Key: EMPTY
API endpoint URL: `http://172.21.56.14:8888/v1` or `http://host.docker.internal:8888/v1`
```

**7.7 Set as Default Models**  
In the top-right `System Model Settings`, set:  
- **Text-to-Speech Model**: `edge-tts`  
- **Speech-to-Text Model**: `SenseVoiceSmall`  
- **Document Rerank Model**: `bge-reranker-base`  
- **Language Model**: `Qwen3-1.7B`  
- **Embedding Model**: `bge-small-zh-v1.5`
Click `Save Settings`.  

**7.8 Use the Models**  
Add any `chatflow`, enter the workflow, and enable `Text-to-Speech` and `Speech-to-Text` features in the top-right `Functions`. Configure the models you added, turn on `Auto-Play`, and start chatting.  

### 8. Connect to MySQL Database in Dify  

**8.1 Connection Configuration**  
Configure MySQL connection details in `.env` file:  
```
MYSQL_HOST="172.21.48.1"  # Replace with your actual IP address (check using `ipconfig | findstr "IPv4"` in cmd)
MYSQL_PORT=3306
MYSQL_USER="root"
MYSQL_PASSWORD="root"
MYSQL_DATABASE="any4any"  # Replace with your database name
```  

**8.2 MySQL Database Configuration**  
Run the following commands in MySQL to allow host machine access (172.21.56.14):  
```mysql  
-- Allow host machine (172.21.56.14) to access databases as root  
-- Replace YOUR_PASSWORD with your database password  
GRANT ALL PRIVILEGES ON *.* TO 'root'@'172.21.56.14' IDENTIFIED BY 'YOUR_PASSWORD';  

-- For MySQL 8.0+, create user and grant privileges separately  
CREATE USER 'root'@'172.21.56.14' IDENTIFIED BY 'YOUR_PASSWORD';  
GRANT ALL PRIVILEGES ON *.* TO 'root'@'172.21.56.14';  
```  

**8.3 Build HTTP Request**  
In Dify, add an `HTTP Request Node` to your workflow or chatflow and configure as follows:  
```
Request Method: POST  
Request URL: http://localhost:8888/v1/db/query  
Form-data Parameter Name: query  
Form-data Parameter Value: SELECT * FROM users LIMIT 1  # Example query  
```  

## ğŸ“Project Structure

```
any4any/
â”œâ”€â”€ core/                     # Core functionality modules
â”‚   â”œâ”€â”€ asr/                  # Speech recognition module
â”‚   â”‚   â””â”€â”€ transcription.py  # Audio transcription implementation
â”‚   â”œâ”€â”€ auth/                 # Authentication module
â”‚   â”‚   â””â”€â”€ model_auth.py     # Model authentication implementation
â”‚   â”œâ”€â”€ chat/                 # Chat-related modules
â”‚   â”‚   â”œâ”€â”€ conversation_database.py  # Conversation database operations
â”‚   â”‚   â”œâ”€â”€ conversation_manager.py   # Conversation manager
â”‚   â”‚   â”œâ”€â”€ delay_manager.py          # Delay manager
â”‚   â”‚   â”œâ”€â”€ llm.py            # Large language model interface
â”‚   â”‚   â”œâ”€â”€ openai_api.py     # OpenAI API compatible interface
â”‚   â”‚   â””â”€â”€ preview.py        # Preview functionality implementation
â”‚   â”œâ”€â”€ database/             # Database module
â”‚   â”‚   â””â”€â”€ database.py       # Database connection and query implementation
â”‚   â”œâ”€â”€ dingtalk/             # DingTalk bot module
â”‚   â”‚   â””â”€â”€ message_manager.py # DingTalk message processing
â”‚   â”œâ”€â”€ embedding/            # Embedding model module
â”‚   â”‚   â”œâ”€â”€ document_processor.py     # Document processor
â”‚   â”‚   â”œâ”€â”€ embedding_manager.py      # Embedding manager
â”‚   â”‚   â”œâ”€â”€ kb_server.py              # Knowledge base server
â”‚   â”‚   â”œâ”€â”€ openai_api.py             # OpenAI API interface
â”‚   â”‚   â”œâ”€â”€ retrieval_engine.py       # Retrieval engine
â”‚   â”‚   â””â”€â”€ vector_store.py           # Vector store
â”‚   â”œâ”€â”€ lifespan.py           # Application lifecycle management
â”‚   â”œâ”€â”€ log.py                # Log management
â”‚   â”œâ”€â”€ mcp/                  # MCP protocol module
â”‚   â”‚   â””â”€â”€ mcp_tools.py      # MCP tools implementation
â”‚   â”œâ”€â”€ rerank/               # Document reranking module
â”‚   â”‚   â””â”€â”€ rerank.py         # Document reranking implementation
â”‚   â”œâ”€â”€ tts/                  # Text-to-speech module
â”‚   â”‚   â”œâ”€â”€ file.py           # Audio file processing
â”‚   â”‚   â””â”€â”€ speech.py         # Speech synthesis implementation
â”‚   â””â”€â”€ model_manager.py      # Model manager
â”œâ”€â”€ data_models/              # Data model definitions
â”‚   â”œâ”€â”€ Auth.py               # Authentication related models
â”‚   â”œâ”€â”€ Preview.py            # Preview related models
â”‚   â””â”€â”€ model.py              # Base model class
â”œâ”€â”€ servers/                  # Server modules
â”œâ”€â”€ static/                   # Static resource files
â”œâ”€â”€ utils/                    # Utility modules
â”œâ”€â”€ workflows/                # Workflows and external 
â”œâ”€â”€ app.py                    # Application entry file
â”œâ”€â”€ cli.py                    # Command-line interface
â”œâ”€â”€ config.py                 # Configuration file
â”œâ”€â”€ requirements.txt          # Dependency package list
â”œâ”€â”€ any4any.sql               # Database initialization script
â”œâ”€â”€ a4a-run.sh                # Startup script
â””â”€â”€ .env.example              # Environment variable example file
```

## ğŸŒŸRelated Open-Source Projects  

- edge-tts: https://github.com/rany2/edge-tts
- SenseVoice: https://github.com/FunAudioLLM/SenseVoice
- bge-reranker-base: https://huggingface.co/BAAI/bge-reranker-base
- bge-small-zh-v1.5: https://huggingface.co/BAAI/bge-small-zh-v1.5
- dify: https://github.com/langgenius/dify
- fastapi: https://github.com/fastapi/fastapi
- Qwen3-1.7B: https://huggingface.co/Qwen/Qwen3-1.7B
- Layui: https://github.com/layui/layui
- font-awesome: https://github.com/FortAwesome/Font-Awesome  

## ğŸš§Roadmap  
- Enhance conversation management functionality
- Support more large language models
- Integrate more instant messaging service providers
- Enhance frontend interface for better user experience
- Support more TTS and ASR models
- Add more APIs and services

## ğŸ“Contact Us  
- Official Website: https://eogee.com  
- Email: eogee@qq.com  
- Bilibili: https://space.bilibili.com/315734619  
- Douyin: [æŠ–éŸ³eogee](https://www.douyin.com/user/MS4wLjABAAAAdH5__CXhFJtSrDQKNuI_vh4mI4-LdyQ_LPKB4d9gR3gISMC_Ak0ApCjFYy_oxhfC) (Live streaming nightly at 8 PM).